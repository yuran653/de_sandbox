apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-master-config
  namespace: spark
data:
  spark-defaults.conf: |
    spark.master.ui.retainedApplications=20
    spark.master.ui.retainedDrivers=20
    spark.master.exceptionOnMemoryOverflow=false
    spark.local.dir=/tmp/spark-master
  log4j2.properties: |
    rootLogger.level = info
    appender.console.type = Console
    appender.console.name = console
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n
    rootLogger.appenderRef.console.ref = console
    # Silence NativeCodeLoader check
    logger.hadoop.name = org.apache.hadoop.util.NativeCodeLoader
    logger.hadoop.level = error

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: spark-worker-config
  namespace: spark
data:
  spark-defaults.conf: |
    # Note: Executor resources are typically set by user code
    # These are fallback defaults only
    spark.executor.cores=1
    spark.executor.memory=1g
    spark.executor.memoryOverhead=128m
    spark.worker.cleanup.enabled=true
    spark.worker.cleanup.interval=3600
    spark.worker.cleanup.appDataTtl=10800
    spark.worker.timeout=120
    spark.task.cpus=1
    spark.task.maxFailures=4
    spark.scheduler.mode=FIFO
    spark.local.dir=/tmp/spark-worker
    spark.eventLog.dir=/var/spark-events
    spark.history.fs.logDirectory=/var/spark-events
  log4j2.properties: |
    rootLogger.level = info
    appender.console.type = Console
    appender.console.name = console
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n
    rootLogger.appenderRef.console.ref = console
    # Silence NativeCodeLoader check
    logger.hadoop.name = org.apache.hadoop.util.NativeCodeLoader
    logger.hadoop.level = error
