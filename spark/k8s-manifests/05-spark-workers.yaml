apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: spark-worker
  namespace: spark
spec:
  serviceName: spark-worker-headless
  replicas: 2
  selector:
    matchLabels:
      app: spark-worker
  template:
    metadata:
      labels:
        app: spark-worker
    spec:
      containers:
      - name: spark-worker
        image: custom-spark:3.4.4
        imagePullPolicy: IfNotPresent
        # Expose both potential ports since we can't be dynamic here easily
        # but actual listening port is set by command
        ports:
        - containerPort: 30081
          name: webui-0
        - containerPort: 30082
          name: webui-1
        env:
        - name: SPARK_WORKER_CORES
          value: "1"
        - name: SPARK_WORKER_MEMORY
          value: "2g"
        - name: SPARK_WORKER_DIR
          value: "/tmp/spark-worker"
        resources:
          requests:
            cpu: 1200m
            memory: 2560Mi
          limits:
            cpu: 1400m
            memory: 2816Mi
        command:
        - /bin/bash
        - -c
        - |
          # Calculate port based on pod index (spark-worker-0 -> 0)
          POD_INDEX=${HOSTNAME##*-}
          export SPARK_PUBLIC_DNS=10.104.0.4
          export SPARK_WORKER_WEBUI_PORT=$((30081 + POD_INDEX))
          
          echo "Starting worker with WebUI Port: $SPARK_WORKER_WEBUI_PORT and Public DNS: $SPARK_PUBLIC_DNS"
          
          /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker \
            --host $(hostname -i) \
            --webui-port $SPARK_WORKER_WEBUI_PORT \
            --cores 1 \
            --memory 2g \
            spark://spark-master-0.spark-master-headless.spark.svc.cluster.local:7077
        volumeMounts:
        - name: spark-events
          mountPath: /var/spark-events
        - name: spark-worker-config
          mountPath: /opt/spark/conf/spark-defaults.conf
          subPath: spark-defaults.conf
        - name: spark-worker-config
          mountPath: /opt/spark/conf/log4j2.properties
          subPath: log4j2.properties
        livenessProbe:
          exec:
            command:
            - /bin/bash
            - -c
            - pgrep -f 'org.apache.spark.deploy.worker.Worker'
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 5
      initContainers:
      - name: wait-for-master
        image: busybox:latest
        command: ['sh', '-c', 'until nc -z spark-master-0.spark-master-headless.spark.svc.cluster.local 7077; do echo waiting for master; sleep 2; done']
      volumes:
      - name: spark-worker-config
        configMap:
          name: spark-worker-config
  volumeClaimTemplates:
  - metadata:
      name: spark-events
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: local-path
      resources:
        requests:
          storage: 1Gi

---
apiVersion: v1
kind: Service
metadata:
  name: spark-worker-headless
  namespace: spark
spec:
  clusterIP: None
  selector:
    app: spark-worker
  ports:
  - name: webui-0
    port: 30081
    targetPort: 30081
  - name: webui-1
    port: 30082
    targetPort: 30082

---
apiVersion: v1
kind: Service
metadata:
  name: spark-worker-0-ui
  namespace: spark
spec:
  type: NodePort
  selector:
    statefulset.kubernetes.io/pod-name: spark-worker-0
  ports:
  - name: webui
    port: 30081
    targetPort: 30081
    nodePort: 30081

---
apiVersion: v1
kind: Service
metadata:
  name: spark-worker-1-ui
  namespace: spark
spec:
  type: NodePort
  selector:
    statefulset.kubernetes.io/pod-name: spark-worker-1
  ports:
  - name: webui
    port: 30082
    targetPort: 30082
    nodePort: 30082
